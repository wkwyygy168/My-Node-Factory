import requests
import re
import base64
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor

def fetch_and_decode(url):
    """æš´åŠ›æ”¶å‰²æ¨¡å¼ï¼šåªè¦ç½‘é¡µæœ‰ä¸œè¥¿ï¼Œå…¨éƒ¨æŠ“å›æ¥"""
    # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ï¼Œé˜²æ­¢éƒ¨åˆ†æºï¼ˆå¦‚ Gistï¼‰æ‹¦æˆª
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    try:
        r = requests.get(url, headers=headers, timeout=15)
        if r.status_code == 200:
            content = r.text.strip()
            # åè®®æŒ‡çº¹è¯†åˆ«ï¼šæ¶µç›–ä¸»æµæ‰€æœ‰åè®®
            pattern = r'(?:ss|ssr|vmess|vless|trojan|hy2|tuic)://[^\s<>"]+'
            
            # 1. æŠ“å–æ˜æ–‡ï¼ˆé’ˆå¯¹ YAML å’Œ æ–‡æœ¬æ ¼å¼ï¼‰
            found = re.findall(pattern, content, re.I)
            
            # 2. å°è¯• Base64 æš´åŠ›è§£ç ï¼ˆé’ˆå¯¹ Base64.txt è¿™ç§çº¯å¯†æ–‡æ ¼å¼ï¼‰
            try:
                # è‡ªåŠ¨è¡¥å…¨å¡«å……ç¬¦
                missing_padding = len(content) % 4
                if missing_padding:
                    content += "=" * (4 - missing_padding)
                decoded = base64.b64decode(content).decode('utf-8', errors='ignore')
                found.extend(re.findall(pattern, decoded, re.I))
            except:
                pass
            return found
    except:
        return []

def get_dynamic_urls():
    """å…·å¤‡è‡ªåŠ¨æ—¥æœŸè®¡ç®—èƒ½åŠ›ï¼šç”Ÿæˆæœ€è¿‘ 10 å¤©çš„ nodefree é“¾æ¥"""
    dynamic_list = []
    today = datetime.now()
    for i in range(10):
        target_date = today - timedelta(days=i)
        date_str = target_date.strftime("%Y%m%d")
        month_str = target_date.strftime("%m")
        year_str = target_date.strftime("%Y")
        url = f"https://node.nodefree.me/{year_str}/{month_str}/{date_str}.txt"
        dynamic_list.append(url)
    return dynamic_list

def collector():
    print("ğŸš€ [SYSTEM] å¼•æ“é‡å¯ï¼šæ­£åœ¨åˆæˆåŠ¨æ€æ—¥æœŸæºå¹¶å¼€å¯å¹¶è¡Œæ”¶å‰²...")
    
    # 1. ç”ŸæˆåŠ¨æ€æ—¥æœŸé“¾æ¥
    dynamic_targets = get_dynamic_urls()
    
    # 2. æ ¸å¿ƒæºåˆ—è¡¨ï¼šæ•´åˆä½ æä¾›çš„æœ€æ–°é«˜è´¨é‡æº
    base_targets = [
        # --- è€å¤§æ–°å¢ï¼šBarabama ç³»åˆ— (å«é•œåƒåŠ é€Ÿ) ---
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/yudou66.txt",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/blues.txt",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/clashmeta.txt",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/ndnode.txt",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/nodev2ray.txt",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/nodefree.txt",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/v2rayshare.txt",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/wenode.txt",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/yudou66.yaml",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/blues.yaml",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/clashmeta.yaml",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/ndnode.yaml",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/nodev2ray.yaml",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/nodefree.yaml",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/v2rayshare.yaml",
        "https://gh-proxy.com/raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/wenode.yaml",
        
        # --- è€å¤§æ–°å¢ï¼šshuaidaoya Gist ç³»åˆ— ---
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/base64.txt",
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/all.yaml",
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/mihomo.yaml",
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/history.yaml",

        # --- åŸæœ‰åŸºç¡€æºç²¾é€‰ ---
        "https://raw.githubusercontent.com/freefq/free/master/v2ray",
        "https://raw.githubusercontent.com/vpei/free-node/master/v2ray.txt",
        "https://raw.githubusercontent.com/ssrsub/ssr/master/v2ray",
        "https://raw.githubusercontent.com/snakem982/proxypool/main/source/all.txt",
        "https://raw.githubusercontent.com/mahdibland/SSAggregator/master/sub/sub_merge.txt",
        "https://t.me/s/v2rayfree",
        "https://t.me/s/V2List",
        "https://raw.githubusercontent.com/mianfeifq/share/main/data.txt",
        "https://raw.githubusercontent.com/mksshare/SSR-V2ray-Trojan-Clash-subscription/main/Clash.yaml"
    ]

    # 3. åˆå¹¶æ‰€æœ‰ç›®æ ‡æºå¹¶å»é‡ URL
    targets = list(set(base_targets + dynamic_targets))

    all_found = []
    # å¢åŠ åˆ° 40 çº¿ç¨‹ï¼Œå› ä¸ºæºå¤šäº†ä¸å°‘ï¼Œæé€Ÿæ”¶å‰²
    with ThreadPoolExecutor(max_workers=40) as executor:
        results = executor.map(fetch_and_decode, targets)
        for res in results:
            if res:
                all_found.extend(res)

    # æ ¸å¿ƒï¼šç»™æ¯ä¸ªèŠ‚ç‚¹æ³¨å…¥è€å¤§è¦æ±‚çš„ä¸“å±åç¼€
    suffix = "youtube@å…è´¹å¼€æº"
    tagged_nodes = []
    for node in set(all_found):
        # æ¸…ç†æ—§å¤‡æ³¨ï¼Œæ‰“ä¸Šæ–°æ ‡ç­¾
        base_node = node.split('#')[0]
        tagged_nodes.append(f"{base_node}#{suffix}")

    # 4. è¦†ç›–å†™å…¥ nodes.txt
    with open("nodes.txt", "w", encoding="utf-8") as f:
        if len(tagged_nodes) > 1:
            f.write("\n".join(tagged_nodes))
            print(f"âœ… [SUCCESS] æ•è·å”¯ä¸€èŠ‚ç‚¹: {len(tagged_nodes)} ä¸ªï¼Œå·²åŒæ­¥åç¼€å¹¶æ›´æ–° nodes.txt")
        else:
            f.write(f"ss://YWVzLTI1Ni1jZmI6WG44aktkbURNMDBJZU8lIyQjZkpBTXRzRUFFVU9wSC9ZV1l0WXFERm5UMFNWQDEwMy4xODYuMTU1LjI3OjM4Mzg4#{suffix}")

if __name__ == "__main__":
    collector()
