import requests
import re
import base64
from concurrent.futures import ThreadPoolExecutor

def fetch_pure_nodes(url):
    """åƒæ¬è¿å·¥ä¸€æ ·ï¼Œåªè´Ÿè´£æŠŠèŠ‚ç‚¹ä»ç½‘é¡µé‡ŒæŠ å‡ºæ¥"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    try:
        r = requests.get(url, headers=headers, timeout=20)
        if r.status_code == 200:
            raw_data = r.text.strip()
            # åè®®è¯†åˆ«æ­£åˆ™ï¼šè¿™æ˜¯ç›®å‰æœ€å…¼å®¹çš„å†™æ³•
            pattern = r'(?:ss|ssr|vmess|vless|trojan|hy2|tuic)://[^\s<>"]+'
            
            # 1. å°è¯•ç›´æ¥æå–ï¼ˆå¦‚æœç½‘é¡µé‡Œå·²ç»æ˜¯æ˜æ–‡ï¼‰
            found = re.findall(pattern, raw_data, re.I)
            
            # 2. æš´åŠ›è§£ç  Base64ï¼ˆé’ˆå¯¹ base64.txt è¿™ç§çº¯å¯†æ–‡ï¼‰
            # æˆ‘ä»¬å…ˆå°è¯•å¯¹æ•´ä¸ªç½‘é¡µå†…å®¹è¿›è¡Œ Base64 è§£ç 
            try:
                # è‡ªåŠ¨æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ¢è¡Œç¬¦æˆ–ç©ºæ ¼
                clean_b64 = re.sub(r'\s+', '', raw_data)
                missing_padding = len(clean_b64) % 4
                if missing_padding:
                    clean_b64 += "=" * (4 - missing_padding)
                decoded = base64.b64decode(clean_b64).decode('utf-8', errors='ignore')
                found.extend(re.findall(pattern, decoded, re.I))
            except:
                pass
            return found
    except:
        return []

def collector():
    print("ğŸš€ [PURE-MODE] çº¯å‡€æ¬è¿æ¨¡å¼å¯åŠ¨ï¼šç›®æ ‡ shuaidaoya é»„é‡‘æº...")
    
    # æŒ‰ç…§ä½ çš„è¦æ±‚ï¼Œåªå†™è¿™ä¸¤æ¡ä½ éªŒè¯è¿‡æœ€çŒ›çš„é“¾æ¥
    targets = [
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/base64.txt",
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/all.yaml"
    ]

    all_found = []
    # ä¾ç„¶ä½¿ç”¨å¹¶è¡Œï¼Œé€Ÿåº¦æå¿«
    with ThreadPoolExecutor(max_workers=5) as executor:
        results = executor.map(fetch_pure_nodes, targets)
        for res in results:
            if res:
                all_found.extend(res)

    # æ·±åº¦å»é‡ï¼ˆé˜²æ­¢ä¸¤æ¡é“¾æ¥é‡Œæœ‰é‡å¤èŠ‚ç‚¹ï¼‰
    unique_nodes = list(set(all_found))
    
    # ç›´æ¥å†™å…¥ï¼Œä¸åŠ åç¼€ï¼Œä¸åˆ‡å¤‡æ³¨ï¼Œä¿æŒåŸæ±åŸå‘³
    with open("nodes.txt", "w", encoding="utf-8") as f:
        if len(unique_nodes) > 0:
            f.write("\n".join(unique_nodes))
            print(f"âœ… [SUCCESS] æ¬è¿å®Œæ¯•ï¼å…±è®¡ {len(unique_nodes)} ä¸ªåŸå§‹èŠ‚ç‚¹å·²å…¥åº“ã€‚")
        else:
            print("âŒ [FAILED] æ²¡æŠ“åˆ°èŠ‚ç‚¹ï¼Œè¯·æ£€æŸ¥ GitHub ç½‘ç»œè¿é€šæ€§ã€‚")

if __name__ == "__main__":
    collector()
