import requests
import re
import base64
import time

# ç²¾å‡†æ‰“å‡»ç›®æ ‡ä¸å…¨çƒå¤‡é€‰åº“
TARGETS = [
    # --- æ ¸å¿ƒç›®æ ‡ï¼šä½ æŒ‡å®šçš„ç²¾å“ç«™é•œåƒ ---
    'https://raw.githubusercontent.com/v2rayse/free-node/main/v2ray.txt',
    'https://raw.githubusercontent.com/nodefree/free-nodes/main/nodes/nodes.txt',
    
    # --- å…¨çƒå®æ—¶åŒæ­¥æ±  (é»‘å®¢çº§ä¿åº•) ---
    'https://raw.githubusercontent.com/freefq/free/master/v2ray',
    'https://raw.githubusercontent.com/vpei/free-node/master/v2ray.txt',
    'https://raw.githubusercontent.com/LonUp/NodeList/main/NodeList',
    'https://raw.githubusercontent.com/mianfeifq/share/main/data.txt',
    
    # --- Telegram åŠ¨æ€ç½‘é¡µè§£æ ---
    'https://t.me/s/v2rayfree',
    'https://t.me/s/V2List'
]

def smart_decode(content):
    """é»‘å®¢çº§åŠ¨æ€è§£ç ï¼šè‡ªåŠ¨è¯†åˆ«å¹¶ç ´è§£ Base64 åŠ å¯†"""
    try:
        # å°è¯•è§£ç 
        decoded = base64.b64decode(content).decode('utf-8')
        if "://" in decoded: return decoded
    except:
        pass
    return content

def collector():
    print("ğŸ›°ï¸ [SYSTEM] æ­£åœ¨å¯åŠ¨å…¨çƒèŠ‚ç‚¹å·¡èˆªæ‰«æ...")
    final_nodes = []
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    for url in TARGETS:
        try:
            print(f"ğŸ“¡ [SCANNING] ç›®æ ‡: {url}")
            r = requests.get(url, headers=headers, timeout=25)
            if r.status_code == 200:
                raw_data = r.text
                # å°è¯•å¯¹æ•´ä¸ªç»“æœè¿›è¡Œåˆæ­¥è§£ç 
                processed_data = smart_decode(raw_data)
                
                # ä½¿ç”¨éè´ªå©ªåŒ¹é…ï¼Œç²¾å‡†é”å®šåè®®é“¾æ¥
                found = re.findall(r'(?:vmess|vless|ss|trojan|ssr)://[^\s<>"]+', processed_data)
                
                # å¦‚æœè¿˜æ˜¯ç©ºçš„ï¼Œå°è¯•è¿›è¡ŒäºŒæ¬¡åˆ†æ®µè§£ç ï¼ˆé’ˆå¯¹éƒ¨åˆ†æ··åˆåŠ å¯†æºï¼‰
                if not found:
                    segments = re.findall(r'[A-Za-z0-9+/=]{50,}', raw_data)
                    for seg in segments:
                        found.extend(re.findall(r'(?:vmess|vless|ss|trojan|ssr)://[^\s<>"]+', smart_decode(seg)))
                
                final_nodes.extend(found)
                print(f"âœ… [SUCCESS] æ•è·æ•°æ®æµ: {len(found)} æ¡")
        except Exception as e:
            print(f"âš ï¸ [ERROR] è¿æ¥ä¸­æ–­: {url}")

    # æ·±åº¦å»é‡ä¸æ¸…æ´—
    unique_nodes = sorted(list(set(final_nodes)))
    
    # ç»“æœå†™å…¥
    with open("nodes.txt", "w", encoding="utf-8") as f:
        if unique_nodes:
            f.write("\n".join(unique_nodes))
            print(f"\nğŸ† [FINAL] æ”¶å‰²ä»»åŠ¡åœ†æ»¡å®Œæˆï¼å”¯ä¸€ç²¾å“èµ„äº§: {len(unique_nodes)} ä¸ª")
        else:
            # æœ€åçš„ä¿åº•ï¼šç”Ÿæˆä¸€æ¡ä½ çš„ä¸“å±åšä¸»å±•ç¤ºèŠ‚ç‚¹
            f.write("vmess://ew0KICAiYWRkIjogIjguOC44LjgiLCAiYWlkIjogIjAiLCAiaG9zdCI6ICIiLCAiaWQiOiAiMDAwMDAwMDAtMDAwMC0wMDAwLTAwMDAtMDAwMDAwMDAwMDAwIiwgIm5ldCI6ICJ3cyIsICJwYXRoIjogIiIsICJwb3J0IjogIjQ0MyIsICJwcyI6ICLkv67mlLnlrIzkv67ku6Plm67kuI3ot6_vvIzkvY3nva7mnKrmm7TmlrAiLCAic2N5IjogImF1dG8iLCAic25pIjogIiIsICJ0bHMiOiAibm9uZSIsICJ0eXBlIjogIm5vbmUiLCAidiI6ICIyIn0=")
            print("\nğŸš¨ [ALERT] å…¨çƒæºæš‚æœªäº§å‡ºæ–°æ•°æ®ï¼Œå·²ç»´æŒç³»ç»Ÿçƒ­åº¦ã€‚")

if __name__ == "__main__":
    collector()
