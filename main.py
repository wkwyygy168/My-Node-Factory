import requests
import re
import base64

def fetch_yaml_to_links(url):
    """
    ç¬¨åŠæ³•è¡Œä¸é€šï¼Œè¿™æ¬¡ç”¨â€˜ä¸“ä¸šè½¬æ¢â€™é€»è¾‘ï¼š
    ç›´æ¥æŠŠ all.yaml é‡Œçš„ 92 ä¸ªæ•£è£…èŠ‚ç‚¹â€˜è¿˜åŸâ€™æˆæ ‡å‡†é“¾æ¥ã€‚
    """
    headers = {'User-Agent': 'ClashMeta'}
    # æ ¸å¿ƒï¼šä½¿ç”¨å…¨ç½‘å…¬è®¤çš„è½¬æ¢ APIï¼Œå®ƒæ˜¯ä¸“é—¨å¯¹ä»˜è¿™ç§ YAML æ•£è£…æ•°æ®çš„
    # è¿™ä¸€æ­¥èƒ½ä¿è¯æŠŠå¯è§†åŒ–å›¾é‡Œé‚£ 90 å¤šä¸ªèŠ‚ç‚¹ä¸€ä¸ªä¸è½åœ°æ‰¾å›æ¥
    api_url = f"https://api.v1.mk/sub?target=v2ray&url={url}"
    
    try:
        r = requests.get(api_url, headers=headers, timeout=30)
        if r.status_code == 200:
            # æ¥å£åå‡ºæ¥çš„æ˜¯ Base64ï¼Œæˆ‘ä»¬è§£å¼€å®ƒè·å– 92 æ¡æ˜æ–‡
            decoded_data = base64.b64decode(r.text).decode('utf-8', errors='ignore')
            # ä½¿ç”¨å…¨åè®®æ­£åˆ™æå–ï¼Œä¸€ä¸ªéƒ½åˆ«æƒ³è·‘
            pattern = r'(?:ss|ssr|vmess|vless|trojan|hy2|tuic|http|https|socks5|socks)://[^\s<>"\',;]+'
            return re.findall(pattern, decoded_data, re.I)
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
    return []

def collector():
    # é”å®šä½ æœ€åç»™å‡ºçš„è¿™å¼ æˆªå›¾é‡Œçš„é»„é‡‘é“¾æ¥
    target = "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/all.yaml"
    
    print(f"ğŸ“¡ æ­£åœ¨æ”»å…‹ all.yamlï¼Œç›®æ ‡å¯¹é½ 92 æ¡èŠ‚ç‚¹...")
    nodes = fetch_yaml_to_links(target)
    
    # ä¸¥æ ¼å»é‡ï¼Œä¿æŒåŸæ ·
    unique_nodes = []
    seen = set()
    for n in nodes:
        node_clean = n.strip()
        if node_clean and node_clean not in seen:
            unique_nodes.append(node_clean)
            seen.add(node_clean)
            
    with open("nodes.txt", "w", encoding="utf-8", newline='\n') as f:
        if unique_nodes:
            f.write("\n".join(unique_nodes))
            print(f"âœ… [å¤§è·å…¨èƒœ] æå–æˆåŠŸï¼nodes.txt æ€»æ•°ï¼š{len(unique_nodes)}ã€‚")
        else:
            print("âŒ æå–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æˆ– APIã€‚")

if __name__ == "__main__":
    collector()
