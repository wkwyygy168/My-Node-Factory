import requests
import re
import base64
from concurrent.futures import ThreadPoolExecutor

def recursive_decode(text, depth=0):
    """åƒå‰¥æ´‹è‘±ä¸€æ ·æ·±åº¦è§£ç ï¼Œè§£å†³åªæœ‰1ä¸ªèŠ‚ç‚¹çš„é—®é¢˜"""
    if depth > 5: return text # é˜²æ­¢æ­»å¾ªç¯
    pattern = r'(?:ss|ssr|vmess|vless|trojan|hy2|tuic)://[^\s<>"]+'
    # å°è¯•æ¸…æ´—å¹¶è§£ç 
    try:
        clean_text = re.sub(r'[^a-zA-Z0-9+/=]', '', text)
        if len(clean_text) % 4: clean_text += "=" * (4 - len(clean_text) % 4)
        decoded = base64.b64decode(clean_text).decode('utf-8', errors='ignore')
        if any(p in decoded for p in ['://']):
            return recursive_decode(decoded, depth + 1)
    except: pass
    return text

def fetch_content(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    # å¢åŠ é•œåƒå¤‡é€‰è·¯å¾„
    alt_url = url.replace("raw.githubusercontent.com", "fastly.jsdelivr.net/gh").replace("/master/", "@master/").replace("/main/", "@main/") if "raw.githubusercontent.com" in url else url
    
    for target in [alt_url, url]:
        try:
            r = requests.get(target, headers=headers, timeout=15)
            if r.status_code == 200 and len(r.text) > 10:
                raw = r.text
                # é€’å½’æå–æ‰€æœ‰éšè—èŠ‚ç‚¹
                decoded_content = recursive_decode(raw)
                pattern = r'(?:ss|ssr|vmess|vless|trojan|hy2|tuic)://[^\s<>"]+'
                # åŒæ—¶ä»åŸæ–‡å’Œè§£å¯†æ–‡ä¸­æŠ“å–
                return re.findall(pattern, raw + "\n" + decoded_content, re.I)
        except: continue
    return []

def collector():
    print("ğŸš€ [SYSTEM] å¼•æ“ V12.0ï¼šå¯åŠ¨é€’å½’çˆ†ç ´æ¨¡å¼...")
    # è¿™é‡Œçš„ targets ä¿æŒä½ é‚£ 80 æ¡åˆ—è¡¨ä¸å˜å³å¯
    targets = [ "...ä½ çš„80æ¡é“¾æ¥..." ] 

    all_found = []
    with ThreadPoolExecutor(max_workers=20) as executor:
        results = executor.map(fetch_content, targets)
        for res in results:
            if res: all_found.extend(res)

    unique_nodes = list(set(all_found))
    with open("nodes.txt", "w", encoding="utf-8") as f:
        if len(unique_nodes) > 1:
            f.write("\n".join(unique_nodes))
            print(f"âœ… [SUCCESS] çˆ†ç ´æˆåŠŸï¼æ•è·æœ‰æ•ˆèŠ‚ç‚¹: {len(unique_nodes)} ä¸ª")
        else:
            f.write("ss://YWVzLTI1Ni1jZmI6WG44aktkbURNMDBJZU8lIyQjZkpBTXRzRUFFVU9wSC9ZV1l0WXFERm5UMFNWQDEwMy4xODYuMTU1LjI3OjM4Mzg4#äº‘ç«¯æ”¶å‰²æœºæ­£åœ¨å…¨åŠ›ä½œä¸š_è¯·ç¨ååˆ·æ–°")

if __name__ == "__main__":
    collector()
