import requests
import re
import base64
from concurrent.futures import ThreadPoolExecutor

def fetch_and_decode(url):
    """å€Ÿé‰´ subs-check é€»è¾‘ï¼šå°è¯•é•œåƒåŠ é€Ÿï¼Œå¤±è´¥åˆ™å›é€€åŸå§‹é“¾æ¥"""
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    
    # è‡ªåŠ¨å°† GitHub è½¬æ¢ä¸ºé•œåƒé“¾æ¥ï¼Œé˜²æ­¢ GitHub Actions è¢«æ‹¦æˆª
    alt_url = url.replace("raw.githubusercontent.com", "fastly.jsdelivr.net/gh").replace("/master/", "@master/").replace("/main/", "@main/") if "raw.githubusercontent.com" in url else url
    
    for target_url in [alt_url, url]:
        try:
            r = requests.get(target_url, headers=headers, timeout=15)
            if r.status_code == 200:
                content = r.text.strip()
                # å…¨åè®®è¯†åˆ«
                pattern = r'(?:ss|ssr|vmess|vless|trojan|hy2|tuic)://[^\s<>"]+'
                found = re.findall(pattern, content, re.I)
                
                # æš´åŠ›è§£ç ï¼šè‡ªåŠ¨è¡¥å…¨ Base64 å¡«å……ç¬¦ï¼Œè§£å†³ 1 ä¸ªèŠ‚ç‚¹çš„æ ¸å¿ƒ
                try:
                    b64_str = re.sub(r'[^a-zA-Z0-9+/=]', '', content)
                    missing_padding = len(b64_str) % 4
                    if missing_padding: b64_str += "=" * (4 - missing_padding)
                    decoded = base64.b64decode(b64_str).decode('utf-8', errors='ignore')
                    found.extend(re.findall(pattern, decoded, re.I))
                except: pass
                
                if found: return found
        except: continue
    return []

def collector():
    print("ğŸš€ [SYSTEM] å¼•æ“ V12.0 å¯åŠ¨ï¼šå…¨æºæ·±åº¦çˆ†ç ´æ¨¡å¼...")
    # è¿™é‡Œä¿æŒä½ é‚£ 80 æ¡ targets ä¸å˜
    targets = [
        "https://raw.githubusercontent.com/freefq/free/master/v2ray",
        # ... (æ­¤å¤„è¯·ä¿æŒä½ åŸæœ¬çš„ 80 æ¡åˆ—è¡¨å³å¯)
    ]

    all_found = []
    with ThreadPoolExecutor(max_workers=30) as executor:
        results = executor.map(fetch_and_decode, targets)
        for res in results:
            if res: all_found.extend(res)

    unique_nodes = list(set(all_found))
    with open("nodes.txt", "w", encoding="utf-8") as f:
        if len(unique_nodes) > 1:
            f.write("\n".join(unique_nodes))
            print(f"âœ… [SUCCESS] çˆ†ç ´å®Œæˆï¼æ•è·å”¯ä¸€èŠ‚ç‚¹: {len(unique_nodes)} ä¸ª")
        else:
            # ä¿®æ”¹ä¿åº•ï¼Œç¡®ä¿æ–‡ä»¶ä¸ä¸ºç©ºå¯¼è‡´ Karing æŠ¥é”™
            f.write("ss://YWVzLTI1Ni1jZmI6WG44aktkbURNMDBJZU8lIyQjZkpBTXRzRUFFVU9wSC9ZV1l0WXFERm5UMFNWQDEwMy4xODYuMTU1LjI3OjM4Mzg4#äº‘ç«¯æ”¶å‰²æœºæ­£åœ¨å…¨åŠ›ä½œä¸š_è¯·ç¨ååˆ·æ–°")

if __name__ == "__main__":
    collector()
