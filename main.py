import requests
import re
import base64
from concurrent.futures import ThreadPoolExecutor

def fetch_raw_nodes(url):
    """
    ç»ˆæè¯†åˆ«é€»è¾‘ï¼š
    1. ä¿æŒå¯¹ base64.txt çš„ 100% å®Œç¾æå–ï¼ˆä½ éªŒè¯è¿‡å¥½ç”¨çš„é€»è¾‘ï¼‰ã€‚
    2. å¼•å…¥â€˜è®¢é˜…è½¬æ¢éš§é“â€™ï¼Œå¼ºè¡ŒæŠŠ all.yaml è¿™ç§ç¡¬éª¨å¤´â€˜ç¿»è¯‘â€™æˆ Karing èƒ½è®¤çš„é“¾æ¥ã€‚
    """
    # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    
    # --- é€»è¾‘ A: ä½ çš„â€˜ä¿å‘½â€™é€»è¾‘ (é’ˆå¯¹ base64.txt è¿™ç§æ˜æ–‡æˆ–çº¯ B64 è®¢é˜…) ---
    try:
        r = requests.get(url, headers=headers, timeout=20)
        if r.status_code == 200:
            raw_text = r.text.strip()
            # åè®®è¯†åˆ«æŒ‡çº¹
            pattern = r'(?:ss|ssr|vmess|vless|trojan|hy2|tuic|http|https|socks5|socks)://[^\s<>"\',;]+'
            
            # å°è¯•ç›´æ¥æŠ“å–æ˜æ–‡
            found = re.findall(pattern, raw_text, re.I)
            
            # å°è¯•æ•´ä½“è§£å¯† (base64.txt é€»è¾‘)
            try:
                clean_b64 = re.sub(r'[^A-Za-z0-9+/=]', '', raw_text)
                missing = len(clean_b64) % 4
                if missing: clean_b64 += "=" * (4 - missing)
                decoded = base64.b64decode(clean_b64).decode('utf-8', errors='ignore')
                found.extend(re.findall(pattern, decoded, re.I))
            except: pass
            
            # å¦‚æœä¸Šé¢æŠ“åˆ°äº†ä¸œè¥¿ï¼Œç›´æ¥è¿”å› (æ¯”å¦‚ base64.txt åœºæ™¯)
            if len(found) > 10: return found

        # --- é€»è¾‘ B: å¼ºåˆ¶è½¬æ¢é€»è¾‘ (é’ˆå¯¹ all.yaml è¿™ç§æ²¡æœ‰ :// çš„ç¡¬éª¨å¤´) ---
        # å¦‚æœæ˜¯ YAML æ ¼å¼ï¼Œæˆ‘ä»¬å€Ÿç”¨â€˜ç¿»è¯‘å®˜â€™(åœ¨çº¿åç«¯) æŠŠé…ç½®è½¬æˆæ ‡å‡†é“¾æ¥
        # è¿™ä¹Ÿæ˜¯å…¨ç½‘å¤„ç†è¿™ç±»æ–‡ä»¶çš„é€šç”¨æ ‡å‡†æ–¹æ¡ˆ
        convert_api = f"https://api.v1.mk/sub?target=v2ray&url={url}&insert=false"
        res = requests.get(convert_api, timeout=20)
        if res.status_code == 200:
            # è½¬æ¢åçš„å†…å®¹é€šå¸¸æ˜¯ Base64 åŠ å¯†çš„é“¾æ¥åˆ—è¡¨
            decoded_api = base64.b64decode(res.text).decode('utf-8', errors='ignore')
            # å†æ¬¡ä½¿ç”¨æ­£åˆ™æå–å‡º :// èŠ‚ç‚¹
            return re.findall(r'(?:ss|ssr|vmess|vless|trojan|hy2|tuic|http|https|socks5|socks)://[^\s<>"\',;]+', decoded_api, re.I)
            
    except: pass
    return []

def collector():
    print("ğŸš€ [GOD-LEVEL] æ­£åœ¨æ‰§è¡Œå…¨åè®®å…¼å®¹æ”¶å‰²ï¼ŒåŠ›ä¿ all.yaml ä¸å†â€˜å¤±è¸ªâ€™...")
    
    # æŠŠä¸¤ä¸ªé»„é‡‘é“¾æ¥éƒ½æ”¾è¿›å»ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨è¯†åˆ«å¹¶é‡‡ç”¨ä¸åŒé€»è¾‘å¤„ç†
    targets = [
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/base64.txt",
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/all.yaml"
    ]

    all_found = []
    with ThreadPoolExecutor(max_workers=5) as executor:
        results = executor.map(fetch_raw_nodes, targets)
        for res in results:
            if res: all_found.extend(res)

    # ä¸¥æ ¼å»é‡ï¼šä¿ç•™æœ€åŸå§‹å­—ç¬¦
    unique_nodes = []
    seen = set()
    for node in all_found:
        n = node.strip()
        if n and n not in seen:
            unique_nodes.append(n)
            seen.add(n)
    
    with open("nodes.txt", "w", encoding="utf-8", newline='\n') as f:
        if unique_nodes:
            f.write("\n".join(unique_nodes))
            print(f"âœ… [DONE] ä»»åŠ¡å¤§è·å…¨èƒœï¼å…±æ•è· {len(unique_nodes)} ä¸ªåŸå§‹èŠ‚ç‚¹ã€‚")
        else:
            print("âŒ è­¦å‘Šï¼šä¾ç„¶æœªèƒ½å‘ç°æœ‰æ•ˆèŠ‚ç‚¹ã€‚")

if __name__ == "__main__":
    collector()
