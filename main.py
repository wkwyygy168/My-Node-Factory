import requests
import re
import base64
from concurrent.futures import ThreadPoolExecutor

def stream_extractor(url):
    """æ¨¡ä»¿å®¢æˆ·ç«¯å†…æ ¸çš„æµå¼æ‰«æï¼Œç¡®ä¿ 100% è¿˜åŸæ¯ä¸€ä¸ªå­—èŠ‚"""
    headers = {'User-Agent': 'clash.meta'}
    try:
        r = requests.get(url, headers=headers, timeout=25)
        if r.status_code != 200: return []
        
        raw_text = r.text
        # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰å¯èƒ½çš„åè®®å¤´ä½ç½®
        # ä¸å†ç”¨æ­»æ¿çš„æ­£åˆ™ï¼Œè€Œæ˜¯å…ˆå®šä½ ://
        protocols = ["vmess://", "vless://", "ss://", "ssr://", "trojan://", "hy2://", "tuic://", "http://", "https://", "socks5://", "socks://"]
        nodes = []

        # ç¬¬äºŒæ­¥ï¼šæ˜æ–‡æš´åŠ›æ‰«æ (é’ˆå¯¹ YAML)
        # æ‰«æé€»è¾‘ï¼šæ‰¾åˆ°åè®®å¤´ï¼Œå‘åæå–ï¼Œç›´åˆ°é‡åˆ°å¼•å·ã€ç©ºæ ¼æˆ–éæ³•å­—ç¬¦
        for proto in protocols:
            start_idx = 0
            while True:
                start_idx = raw_text.find(proto, start_idx)
                if start_idx == -1: break
                
                # æå–é€»è¾‘ï¼šå°½å¯èƒ½å‘åæŠ“å–ï¼Œç›´åˆ°é‡åˆ°æ˜æ˜¾çš„åˆ†ç•Œç¬¦
                end_match = re.search(r'[\s"\'<>\{\}\]\[]', raw_text[start_idx:])
                if end_match:
                    node = raw_text[start_idx : start_idx + end_match.start()]
                else:
                    node = raw_text[start_idx:]
                
                nodes.append(node.strip())
                start_idx += len(proto)

        # ç¬¬ä¸‰æ­¥ï¼šBase64 ç¢ç‰‡åŒ–æå– (é’ˆå¯¹ base64.txt)
        # ä¸å†è§£æ•´ä¸ªé¡µé¢ï¼Œè€Œæ˜¯æå–é¡µé¢ä¸­æ‰€æœ‰å¯èƒ½çš„ Base64 å—è¿›è¡Œå°è¯•
        b64_blocks = re.findall(r'[A-Za-z0-9+/=]{40,}', raw_text)
        for block in b64_blocks:
            try:
                # å°è¯•è¡¥é½å¹¶è§£ç 
                pad = len(block) % 4
                if pad: block += "=" * (4 - pad)
                decoded = base64.b64decode(block).decode('utf-8', errors='ignore')
                # åœ¨è§£ç åçš„å†…å®¹é‡Œé‡å¤ä¸Šè¿°åè®®å¤´æ‰«æ
                for proto in protocols:
                    s_idx = 0
                    while True:
                        s_idx = decoded.find(proto, s_idx)
                        if s_idx == -1: break
                        e_match = re.search(r'[\s"\'<>\{\}\]\[]', decoded[s_idx:])
                        node = decoded[s_idx : s_idx + e_match.start()] if e_match else decoded[s_idx:]
                        nodes.append(node.strip())
                        s_idx += len(proto)
            except:
                continue
                
        return nodes
    except:
        return []

def collector():
    print("ğŸš€ [GHOST-SCAN] æ­£åœ¨æ‰§è¡Œå…¨é‡æµå¼æ‰«æï¼Œæ‰¾å›å¤±è¸ªçš„æå“èŠ‚ç‚¹...")
    
    targets = [
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/base64.txt",
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/all.yaml"
    ]

    all_results = []
    with ThreadPoolExecutor(max_workers=5) as executor:
        results = executor.map(stream_extractor, targets)
        for res in results:
            if res: all_results.extend(res)

    # æ·±åº¦å»é‡ï¼šä¿ç•™æœ€åŸå§‹çš„æ•°æ®ç‰¹å¾
    unique_nodes = []
    seen = set()
    for node in all_results:
        # æ¸…é™¤æœ«å°¾å¯èƒ½çš„è„å­—ç¬¦ï¼ˆå¦‚é€—å·ã€æ‹¬å·ï¼‰
        clean_node = re.split(r'[,;\}]', node)[0]
        if clean_node and clean_node not in seen:
            unique_nodes.append(clean_node)
            seen.add(clean_node)
    
    with open("nodes.txt", "w", encoding="utf-8") as f:
        if unique_nodes:
            f.write("\n".join(unique_nodes))
            print(f"âœ… [DONE] æœ€ç»ˆæ”¶é›†åˆ° {len(unique_nodes)} ä¸ªèŠ‚ç‚¹ã€‚")
        else:
            print("âŒ è­¦å‘Šï¼šæœªå‘ç°æœ‰æ•ˆèŠ‚ç‚¹ã€‚")

if __name__ == "__main__":
    collector()
